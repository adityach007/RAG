{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni_i7BT8YSKe",
        "outputId": "f5286ac6-5ef1-45a0-d96b-83b41b1a6dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.13.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.1)\n",
            "Downloading groq-0.13.1-py3-none-any.whl (109 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/109.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key = \"your_groq_api_key\""
      ],
      "metadata": {
        "id": "unyzHCQ8Ya0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generator**"
      ],
      "metadata": {
        "id": "psB3KmROZbrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "client = Groq(api_key = groq_api_key)\n",
        "\n",
        "def call_llm_with_full_text(itext):\n",
        "  text_input = '\\n'.join(itext)\n",
        "  prompt = f\"Please elaborate on the folleoing content: \\n{text_input}\"\n",
        "\n",
        "  try:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert Natural Language Processing exercise expert.\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"1.You can explain read the input and answer in detail\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature = 0.1\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "  except Exception as e:\n",
        "    return str(e)"
      ],
      "metadata": {
        "id": "zr-9M_lnZaOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "# This function is used to wrap 80 characters per line\n",
        "\n",
        "def print_formatted_response(response):\n",
        "  wrapper = textwrap.TextWrapper(width=80)\n",
        "  text_wrapped = wrapper.fill(text=response)\n",
        "\n",
        "  print(\"Response -------------------\")\n",
        "  print(response)\n",
        "  print(\"Formatted response -------------------\")\n",
        "  print(text_wrapped)"
      ],
      "metadata": {
        "id": "XFLeGg4kZd4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data**"
      ],
      "metadata": {
        "id": "G2Enfv0cZhgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_records = [\n",
        "    \"Retrieval Augmented Generation (RAG) represents a sophisticated hybrid approach in the field of artificial intelligence, particularly within the realm of natural language processing (NLP).\",\n",
        "    \"It innovatively combines the capabilities of neural network-based language models with retrieval systems to enhance the generation of text, making it more accurate, informative, and contextually relevant.\",\n",
        "    \"This methodology leverages the strengths of both generative and retrieval architectures to tackle complex tasks that require not only linguistic fluency but also factual correctness and depth of knowledge.\",\n",
        "    \"At the core of Retrieval Augmented Generation (RAG) is a generative model, typically a transformer-based neural network, similar to those used in models like GPT (Generative Pre-trained Transformer) or BERT (Bidirectional Encoder Representations from Transformers).\",\n",
        "    \"This component is responsible for producing coherent and contextually appropriate language outputs based on a mixture of input prompts and additional information fetched by the retrieval component.\",\n",
        "    \"Complementing the language model is the retrieval system, which is usually built on a database of documents or a corpus of texts.\",\n",
        "    \"This system uses techniques from information retrieval to find and fetch documents that are relevant to the input query or prompt.\",\n",
        "    \"The mechanism of relevance determination can range from simple keyword matching to more complex semantic search algorithms which interpret the meaning behind the query to find the best matches.\",\n",
        "    \"This component merges the outputs from the language model and the retrieval system.\",\n",
        "    \"It effectively synthesizes the raw data fetched by the retrieval system into the generative process of the language model.\",\n",
        "    \"The integrator ensures that the information from the retrieval system is seamlessly incorporated into the final text output, enhancing the model's ability to generate responses that are not only fluent and grammatically correct but also rich in factual details and context-specific nuances.\",\n",
        "    \"When a query or prompt is received, the system first processes it to understand the requirement or the context.\",\n",
        "    \"Based on the processed query, the retrieval system searches through its database to find relevant documents or information snippets.\",\n",
        "    \"This retrieval is guided by the similarity of content in the documents to the query, which can be determined through various techniques like vector embeddings or semantic similarity measures.\",\n",
        "    \"The retrieved documents are then fed into the language model.\",\n",
        "    \"In some implementations, this integration happens at the token level, where the model can access and incorporate specific pieces of information from the retrieved texts dynamically as it generates each part of the response.\",\n",
        "    \"The language model, now augmented with direct access to retrieved information, generates a response.\",\n",
        "    \"This response is not only influenced by the training of the model but also by the specific facts and details contained in the retrieved documents, making it more tailored and accurate.\",\n",
        "    \"By directly incorporating information from external sources, Retrieval Augmented Generation (RAG) models can produce responses that are more factual and relevant to the given query.\",\n",
        "    \"This is particularly useful in domains like medical advice, technical support, and other areas where precision and up-to-date knowledge are crucial.\",\n",
        "    \"Retrieval Augmented Generation (RAG) systems can dynamically adapt to new information since they retrieve data in real-time from their databases.\",\n",
        "    \"This allows them to remain current with the latest knowledge and trends without needing frequent retraining.\",\n",
        "    \"With access to a wide range of documents, Retrieval Augmented Generation (RAG) systems can provide detailed and nuanced answers that a standalone language model might not be capable of generating based solely on its pre-trained knowledge.\",\n",
        "    \"While Retrieval Augmented Generation (RAG) offers substantial benefits, it also comes with its challenges.\",\n",
        "    \"These include the complexity of integrating retrieval and generation systems, the computational overhead associated with real-time data retrieval, and the need for maintaining a large, up-to-date, and high-quality database of retrievable texts.\",\n",
        "    \"Furthermore, ensuring the relevance and accuracy of the retrieved information remains a significant challenge, as does managing the potential for introducing biases or errors from the external sources.\",\n",
        "    \"In summary, Retrieval Augmented Generation represents a significant advancement in the field of artificial intelligence, merging the best of retrieval-based and generative technologies to create systems that not only understand and generate natural language but also deeply comprehend and utilize the vast amounts of information available in textual form.\",\n",
        "    \"A RAG vector store is a database or dataset that contains vectorized data points.\"\n",
        "]"
      ],
      "metadata": {
        "id": "Ux_7mSD-Zf0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_cosine_similarity(text1, text2):\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        stop_words='english',\n",
        "        use_idf=True,\n",
        "        norm='l2',\n",
        "        ngram_range=(1, 2),  # Use unigrams and bigrams\n",
        "        sublinear_tf=True,   # Apply sublinear TF scaling\n",
        "        analyzer='word'      # You could also experiment with 'char' or 'char_wb' for character-level features\n",
        "    )\n",
        "    tfidf = vectorizer.fit_transform([text1, text2])\n",
        "    similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
        "    return similarity[0][0]"
      ],
      "metadata": {
        "id": "JtGbDX8wam_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "    return synonyms\n",
        "\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text.lower())\n",
        "    lemmatized_words = []\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct:\n",
        "            continue\n",
        "        lemmatized_words.append(token.lemma_)\n",
        "    return lemmatized_words\n",
        "\n",
        "def expand_with_synonyms(words):\n",
        "    expanded_words = words.copy()\n",
        "    for word in words:\n",
        "        expanded_words.extend(get_synonyms(word))\n",
        "    return expanded_words\n",
        "\n",
        "def calculate_enhanced_similarity(text1, text2):\n",
        "    # Preprocess and tokenize texts\n",
        "    words1 = preprocess_text(text1)\n",
        "    words2 = preprocess_text(text2)\n",
        "\n",
        "    # Expand with synonyms\n",
        "    words1_expanded = expand_with_synonyms(words1)\n",
        "    words2_expanded = expand_with_synonyms(words2)\n",
        "\n",
        "    # Count word frequencies\n",
        "    freq1 = Counter(words1_expanded)\n",
        "    freq2 = Counter(words2_expanded)\n",
        "\n",
        "    # Create a set of all unique words\n",
        "    unique_words = set(freq1.keys()).union(set(freq2.keys()))\n",
        "\n",
        "    # Create frequency vectors\n",
        "    vector1 = [freq1[word] for word in unique_words]\n",
        "    vector2 = [freq2[word] for word in unique_words]\n",
        "\n",
        "    # Convert lists to numpy arrays\n",
        "    vector1 = np.array(vector1)\n",
        "    vector2 = np.array(vector2)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    cosine_similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
        "\n",
        "    return cosine_similarity\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ROxg3KAaqCK",
        "outputId": "5fc76581-e0eb-4cd6-a636-67a5bf5513f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "paragraph = ' '.join(db_records)          # Joins the db_records text into a single line string\n",
        "wrapper = textwrap.TextWrapper(width=80)  # Creates wrapper of 80 characters per line\n",
        "text_wrapped = wrapper.fill(text = paragraph)\n",
        "\n",
        "print(text_wrapped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucg8R29vZjWv",
        "outputId": "6ca15619-dea1-4a09-8173-d7a3701412d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieval Augmented Generation (RAG) represents a sophisticated hybrid approach\n",
            "in the field of artificial intelligence, particularly within the realm of\n",
            "natural language processing (NLP). It innovatively combines the capabilities of\n",
            "neural network-based language models with retrieval systems to enhance the\n",
            "generation of text, making it more accurate, informative, and contextually\n",
            "relevant. This methodology leverages the strengths of both generative and\n",
            "retrieval architectures to tackle complex tasks that require not only linguistic\n",
            "fluency but also factual correctness and depth of knowledge. At the core of\n",
            "Retrieval Augmented Generation (RAG) is a generative model, typically a\n",
            "transformer-based neural network, similar to those used in models like GPT\n",
            "(Generative Pre-trained Transformer) or BERT (Bidirectional Encoder\n",
            "Representations from Transformers). This component is responsible for producing\n",
            "coherent and contextually appropriate language outputs based on a mixture of\n",
            "input prompts and additional information fetched by the retrieval component.\n",
            "Complementing the language model is the retrieval system, which is usually built\n",
            "on a database of documents or a corpus of texts. This system uses techniques\n",
            "from information retrieval to find and fetch documents that are relevant to the\n",
            "input query or prompt. The mechanism of relevance determination can range from\n",
            "simple keyword matching to more complex semantic search algorithms which\n",
            "interpret the meaning behind the query to find the best matches. This component\n",
            "merges the outputs from the language model and the retrieval system. It\n",
            "effectively synthesizes the raw data fetched by the retrieval system into the\n",
            "generative process of the language model. The integrator ensures that the\n",
            "information from the retrieval system is seamlessly incorporated into the final\n",
            "text output, enhancing the model's ability to generate responses that are not\n",
            "only fluent and grammatically correct but also rich in factual details and\n",
            "context-specific nuances. When a query or prompt is received, the system first\n",
            "processes it to understand the requirement or the context. Based on the\n",
            "processed query, the retrieval system searches through its database to find\n",
            "relevant documents or information snippets. This retrieval is guided by the\n",
            "similarity of content in the documents to the query, which can be determined\n",
            "through various techniques like vector embeddings or semantic similarity\n",
            "measures. The retrieved documents are then fed into the language model. In some\n",
            "implementations, this integration happens at the token level, where the model\n",
            "can access and incorporate specific pieces of information from the retrieved\n",
            "texts dynamically as it generates each part of the response. The language model,\n",
            "now augmented with direct access to retrieved information, generates a response.\n",
            "This response is not only influenced by the training of the model but also by\n",
            "the specific facts and details contained in the retrieved documents, making it\n",
            "more tailored and accurate. By directly incorporating information from external\n",
            "sources, Retrieval Augmented Generation (RAG) models can produce responses that\n",
            "are more factual and relevant to the given query. This is particularly useful in\n",
            "domains like medical advice, technical support, and other areas where precision\n",
            "and up-to-date knowledge are crucial. Retrieval Augmented Generation (RAG)\n",
            "systems can dynamically adapt to new information since they retrieve data in\n",
            "real-time from their databases. This allows them to remain current with the\n",
            "latest knowledge and trends without needing frequent retraining. With access to\n",
            "a wide range of documents, Retrieval Augmented Generation (RAG) systems can\n",
            "provide detailed and nuanced answers that a standalone language model might not\n",
            "be capable of generating based solely on its pre-trained knowledge. While\n",
            "Retrieval Augmented Generation (RAG) offers substantial benefits, it also comes\n",
            "with its challenges. These include the complexity of integrating retrieval and\n",
            "generation systems, the computational overhead associated with real-time data\n",
            "retrieval, and the need for maintaining a large, up-to-date, and high-quality\n",
            "database of retrievable texts. Furthermore, ensuring the relevance and accuracy\n",
            "of the retrieved information remains a significant challenge, as does managing\n",
            "the potential for introducing biases or errors from the external sources. In\n",
            "summary, Retrieval Augmented Generation represents a significant advancement in\n",
            "the field of artificial intelligence, merging the best of retrieval-based and\n",
            "generative technologies to create systems that not only understand and generate\n",
            "natural language but also deeply comprehend and utilize the vast amounts of\n",
            "information available in textual form. A RAG vector store is a database or\n",
            "dataset that contains vectorized data points.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Query**"
      ],
      "metadata": {
        "id": "ljGaxuH9Znvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"define a rag store\""
      ],
      "metadata": {
        "id": "8vV9M69RZl9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(query)\n",
        "print_formatted_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctj7V0o_Zo95",
        "outputId": "d2e1c6ea-6ebd-4987-c8fa-05107934c2f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response -------------------\n",
            "It appears that the given content is a set of letters, each on a new line, forming a vertical arrangement. Let's break it down and analyze the possible meaning or interpretation:\n",
            "\n",
            "1. **Vertical Arrangement**: The letters are arranged vertically, which could be a deliberate attempt to convey a message or create a visual effect. This arrangement might be used to draw attention to specific letters or to create a sense of rhythm.\n",
            "\n",
            "2. **Individual Letters**: The letters are:\n",
            "   - d\n",
            "   - e\n",
            "   - f\n",
            "   - i\n",
            "   - n\n",
            "   - e\n",
            "   - a\n",
            "   - r\n",
            "   - a\n",
            "   - g\n",
            "   - s\n",
            "   - t\n",
            "   - o\n",
            "   - r\n",
            "   - e\n",
            "\n",
            "3. **Possible Words**: Upon closer inspection, it seems that these letters can be rearranged to form several words, including:\n",
            "   - define\n",
            "   - store\n",
            "   - rage\n",
            "   - age\n",
            "   - torn\n",
            "   - tore\n",
            "   - east\n",
            "   - dare\n",
            "   - fine\n",
            "   - fare\n",
            "\n",
            "4. **Meaning and Context**: Without additional context, it's challenging to determine the intended meaning or message. However, some possible interpretations could be:\n",
            "   - **Definition and Storage**: The presence of the words \"define\" and \"store\" might suggest a connection to knowledge, data, or information storage and management.\n",
            "   - **Emotional State**: The word \"rage\" could indicate a strong emotional state, while \"age\" might refer to a stage in life or a time period.\n",
            "   - **Direction and Location**: The word \"east\" could be related to geography or direction.\n",
            "\n",
            "5. **Natural Language Processing (NLP) Perspective**: From an NLP standpoint, this arrangement of letters can be seen as a creative or artistic expression. It might be used as a prompt for language generation, where a model is asked to generate text based on the given letters or words. Alternatively, it could be used as a test case for word recognition, language understanding, or text analysis algorithms.\n",
            "\n",
            "In conclusion, the given content is an intriguing arrangement of letters that can be interpreted in various ways. While it's difficult to determine the intended meaning without additional context, it can be seen as a creative expression, a puzzle, or a test case for NLP algorithms.\n",
            "Formatted response -------------------\n",
            "It appears that the given content is a set of letters, each on a new line,\n",
            "forming a vertical arrangement. Let's break it down and analyze the possible\n",
            "meaning or interpretation:  1. **Vertical Arrangement**: The letters are\n",
            "arranged vertically, which could be a deliberate attempt to convey a message or\n",
            "create a visual effect. This arrangement might be used to draw attention to\n",
            "specific letters or to create a sense of rhythm.  2. **Individual Letters**: The\n",
            "letters are:    - d    - e    - f    - i    - n    - e    - a    - r    - a    -\n",
            "g    - s    - t    - o    - r    - e  3. **Possible Words**: Upon closer\n",
            "inspection, it seems that these letters can be rearranged to form several words,\n",
            "including:    - define    - store    - rage    - age    - torn    - tore    -\n",
            "east    - dare    - fine    - fare  4. **Meaning and Context**: Without\n",
            "additional context, it's challenging to determine the intended meaning or\n",
            "message. However, some possible interpretations could be:    - **Definition and\n",
            "Storage**: The presence of the words \"define\" and \"store\" might suggest a\n",
            "connection to knowledge, data, or information storage and management.    -\n",
            "**Emotional State**: The word \"rage\" could indicate a strong emotional state,\n",
            "while \"age\" might refer to a stage in life or a time period.    - **Direction\n",
            "and Location**: The word \"east\" could be related to geography or direction.  5.\n",
            "**Natural Language Processing (NLP) Perspective**: From an NLP standpoint, this\n",
            "arrangement of letters can be seen as a creative or artistic expression. It\n",
            "might be used as a prompt for language generation, where a model is asked to\n",
            "generate text based on the given letters or words. Alternatively, it could be\n",
            "used as a test case for word recognition, language understanding, or text\n",
            "analysis algorithms.  In conclusion, the given content is an intriguing\n",
            "arrangement of letters that can be interpreted in various ways. While it's\n",
            "difficult to determine the intended meaning without additional context, it can\n",
            "be seen as a creative expression, a puzzle, or a test case for NLP algorithms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advanced RAG**"
      ],
      "metadata": {
        "id": "mP3X1-aiZ4Kv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Vector search**"
      ],
      "metadata": {
        "id": "agX_BhxMZ8dJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Search Function**"
      ],
      "metadata": {
        "id": "o634TzdcaCxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_match(text, records):\n",
        "  best_score = 0\n",
        "  best_record = None\n",
        "\n",
        "  for record in records:\n",
        "    current_score = calculate_cosine_similarity(text, record)\n",
        "\n",
        "    if current_score > best_score:\n",
        "      best_score = current_score\n",
        "      best_record = record\n",
        "\n",
        "  return best_score, best_record"
      ],
      "metadata": {
        "id": "2Bnu3GsCZ1jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_similarity_score, best_matching_record = find_best_match(query, db_records)\n",
        "print_formatted_response(best_matching_record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyIodhnKa_70",
        "outputId": "1aba7c01-fe66-4641-ce76-e29cf9986a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response -------------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Formatted response -------------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Metrics**"
      ],
      "metadata": {
        "id": "v8ZrHGHSb1Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIPnx5oGboS7",
        "outputId": "b84e4944-df31-4031-b418-bd9be3468687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Cosine Similarity Score: 0.126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Similarity\n",
        "\n",
        "response = best_matching_record\n",
        "print(query,\": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, best_matching_record)\n",
        "print(f\"Enhanced Similarity:, {similarity_score:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZKqDlX3b5-G",
        "outputId": "b72165f9-b1c0-4932-c720-3c39fbea5099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Enhanced Similarity:, 0.642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Augmented Input**"
      ],
      "metadata": {
        "id": "g2_F4REucI8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_input = query+\": \"+best_matching_record"
      ],
      "metadata": {
        "id": "fFpBoVdVb9T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_formatted_response(augmented_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Aj1jHtXcLhd",
        "outputId": "d081849c-6c65-4dc2-fae7-c0da1bfdcbfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response -------------------\n",
            "define a rag store: A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Formatted response -------------------\n",
            "define a rag store: A RAG vector store is a database or dataset that contains\n",
            "vectorized data points.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generation**"
      ],
      "metadata": {
        "id": "_HhTmg-0cPp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6kVlpf2cOAp",
        "outputId": "8e53b27f-8ed0-43a0-c695-d9b484b09a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response -------------------\n",
            "The given content appears to be a definition of a specific term, presented in a unique, spaced-out format. Let's break it down and read it in a more conventional way:\n",
            "\n",
            "\"Define a RAG vector store: A RAG vector store is a database or dataset that contains vectorized data points.\"\n",
            "\n",
            "To elaborate on this, a RAG (Relational Algebra Graph) vector store is a type of data storage system that is designed to efficiently manage and query large amounts of vectorized data. Vectorized data refers to data that has been converted into a numerical representation, typically in the form of vectors or matrices, to enable efficient processing and analysis using machine learning algorithms.\n",
            "\n",
            "In the context of Natural Language Processing (NLP), vectorized data can represent words, phrases, or documents as numerical vectors, allowing for semantic similarity calculations, clustering, and other types of analysis. A RAG vector store is optimized for storing and querying these vectorized data points, enabling fast and efficient retrieval of relevant information.\n",
            "\n",
            "Some key characteristics of a RAG vector store include:\n",
            "\n",
            "1. **Vectorized data**: The data is stored in a vectorized format, allowing for efficient processing and analysis.\n",
            "2. **Relational algebra**: The data is organized using relational algebra, which provides a mathematical framework for managing and querying complex data relationships.\n",
            "3. **Graph-based structure**: The data is stored in a graph-based structure, which enables efficient querying and retrieval of related data points.\n",
            "4. **Scalability**: RAG vector stores are designed to handle large amounts of data and scale horizontally to support high-performance querying and analysis.\n",
            "\n",
            "RAG vector stores have applications in various areas, including:\n",
            "\n",
            "1. **Natural Language Processing (NLP)**: For tasks such as text classification, sentiment analysis, and information retrieval.\n",
            "2. **Recommendation systems**: For building personalized recommendation systems that rely on vectorized user and item representations.\n",
            "3. **Computer vision**: For tasks such as image classification, object detection, and image retrieval.\n",
            "\n",
            "In summary, a RAG vector store is a specialized database or dataset that is optimized for storing and querying vectorized data points, particularly in the context of NLP and other machine learning applications.\n",
            "Formatted response -------------------\n",
            "The given content appears to be a definition of a specific term, presented in a\n",
            "unique, spaced-out format. Let's break it down and read it in a more\n",
            "conventional way:  \"Define a RAG vector store: A RAG vector store is a database\n",
            "or dataset that contains vectorized data points.\"  To elaborate on this, a RAG\n",
            "(Relational Algebra Graph) vector store is a type of data storage system that is\n",
            "designed to efficiently manage and query large amounts of vectorized data.\n",
            "Vectorized data refers to data that has been converted into a numerical\n",
            "representation, typically in the form of vectors or matrices, to enable\n",
            "efficient processing and analysis using machine learning algorithms.  In the\n",
            "context of Natural Language Processing (NLP), vectorized data can represent\n",
            "words, phrases, or documents as numerical vectors, allowing for semantic\n",
            "similarity calculations, clustering, and other types of analysis. A RAG vector\n",
            "store is optimized for storing and querying these vectorized data points,\n",
            "enabling fast and efficient retrieval of relevant information.  Some key\n",
            "characteristics of a RAG vector store include:  1. **Vectorized data**: The data\n",
            "is stored in a vectorized format, allowing for efficient processing and\n",
            "analysis. 2. **Relational algebra**: The data is organized using relational\n",
            "algebra, which provides a mathematical framework for managing and querying\n",
            "complex data relationships. 3. **Graph-based structure**: The data is stored in\n",
            "a graph-based structure, which enables efficient querying and retrieval of\n",
            "related data points. 4. **Scalability**: RAG vector stores are designed to\n",
            "handle large amounts of data and scale horizontally to support high-performance\n",
            "querying and analysis.  RAG vector stores have applications in various areas,\n",
            "including:  1. **Natural Language Processing (NLP)**: For tasks such as text\n",
            "classification, sentiment analysis, and information retrieval. 2.\n",
            "**Recommendation systems**: For building personalized recommendation systems\n",
            "that rely on vectorized user and item representations. 3. **Computer vision**:\n",
            "For tasks such as image classification, object detection, and image retrieval.\n",
            "In summary, a RAG vector store is a specialized database or dataset that is\n",
            "optimized for storing and querying vectorized data points, particularly in the\n",
            "context of NLP and other machine learning applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While vector search significantly speeds up the process of finding relevant documents by sequentially going through each record, its efficiency can decrease as the dataset size increases. To address this scalability issue, indexed search offers a more advanced solution."
      ],
      "metadata": {
        "id": "dK1VvBvtcYlx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Index-based Search**"
      ],
      "metadata": {
        "id": "n-HZ_JTMcZdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Index-based search compares the vector of a user query not with the direct vector of a document’s content but with an indexed vector that represents this content."
      ],
      "metadata": {
        "id": "UKjd-9ARciaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Search Function**"
      ],
      "metadata": {
        "id": "SrGDwykcculK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def setup_vectorizer(records):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(records)\n",
        "    return vectorizer, tfidf_matrix\n",
        "\n",
        "def find_best_match(query, vectorizer, tfidf_matrix):\n",
        "    query_tfidf = vectorizer.transform([query])\n",
        "    similarities = cosine_similarity(query_tfidf, tfidf_matrix)\n",
        "    best_index = similarities.argmax()  # Get the index of the highest similarity score\n",
        "    best_score = similarities[0, best_index]\n",
        "    return best_score, best_index\n",
        "\n",
        "vectorizer, tfidf_matrix = setup_vectorizer(db_records)\n",
        "\n",
        "best_similarity_score, best_index = find_best_match(query, vectorizer, tfidf_matrix)\n",
        "best_matching_record = db_records[best_index]\n",
        "\n",
        "print_formatted_response(best_matching_record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4OrdG4HcRbj",
        "outputId": "6b7f7f8c-4530-41ba-9df7-c585026af645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response -------------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Formatted response -------------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Metrics**"
      ],
      "metadata": {
        "id": "0fc4WeFdc8Ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine Similarity\n",
        "\n",
        "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")\n",
        "print_formatted_response(best_matching_record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJiMRlqKcwiX",
        "outputId": "d4da0fa1-5d59-4bc8-c61c-e4098277655c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Cosine Similarity Score: 0.407\n",
            "Response -------------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Formatted response -------------------\n",
            "A RAG vector store is a database or dataset that contains vectorized data\n",
            "points.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Similarity\n",
        "\n",
        "response = best_matching_record\n",
        "print(query,\": \", response)\n",
        "similarity_score = calculate_enhanced_similarity(query, response)\n",
        "print(f\"Enhanced Similarity:, {similarity_score:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rru5xIuWc_eJ",
        "outputId": "4435887f-205f-41ab-d9db-10682dc2bebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Enhanced Similarity:, 0.642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature extraction**"
      ],
      "metadata": {
        "id": "o1Hr9J9IdD0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def setup_vectorizer(records):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(records)\n",
        "\n",
        "    # Convert the TF-IDF matrix to a DataFrame for display purposes\n",
        "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "    # Display the DataFrame\n",
        "    print(tfidf_df)\n",
        "\n",
        "    return vectorizer, tfidf_matrix\n",
        "\n",
        "vectorizer, tfidf_matrix = setup_vectorizer(db_records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J1-9XlYdCHF",
        "outputId": "20461f2f-cff8-4692-bc1f-f31d127f2c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ability    access  accuracy  accurate     adapt  additional  advancement  \\\n",
            "0   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "1   0.000000  0.000000  0.000000  0.216364  0.000000    0.000000     0.000000   \n",
            "2   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "3   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "4   0.000000  0.000000  0.000000  0.000000  0.000000    0.236479     0.000000   \n",
            "5   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "6   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "7   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "8   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "9   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "10  0.186734  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "11  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "12  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "13  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "14  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "15  0.000000  0.172624  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "16  0.000000  0.317970  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "17  0.000000  0.000000  0.000000  0.206861  0.000000    0.000000     0.000000   \n",
            "18  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "19  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "20  0.000000  0.000000  0.000000  0.000000  0.275802    0.000000     0.000000   \n",
            "21  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "22  0.000000  0.174772  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "23  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "24  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "25  0.000000  0.000000  0.228743  0.000000  0.000000    0.000000     0.000000   \n",
            "26  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.173327   \n",
            "27  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
            "\n",
            "      advice  algorithms    allows  ...    vector  vectorized      when  \\\n",
            "0   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "1   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "2   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "3   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "4   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "5   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "6   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "7   0.000000    0.220687  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "8   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "9   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "10  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "11  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.295573   \n",
            "12  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "13  0.000000    0.000000  0.000000  ...  0.200131     0.00000  0.000000   \n",
            "14  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "15  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "16  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "17  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "18  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "19  0.244401    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "20  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "21  0.000000    0.000000  0.291503  ...  0.000000     0.00000  0.000000   \n",
            "22  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "23  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "24  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "25  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "26  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
            "27  0.000000    0.000000  0.000000  ...  0.307719     0.34589  0.000000   \n",
            "\n",
            "       where     which    while     wide      with    within   without  \n",
            "0   0.000000  0.000000  0.00000  0.00000  0.000000  0.260582  0.000000  \n",
            "1   0.000000  0.000000  0.00000  0.00000  0.160278  0.000000  0.000000  \n",
            "2   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "3   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "4   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "5   0.000000  0.247710  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "6   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "7   0.000000  0.179053  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "8   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "9   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "10  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "11  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "12  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "13  0.000000  0.182517  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "14  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "15  0.189283  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "16  0.000000  0.000000  0.00000  0.00000  0.258278  0.000000  0.000000  \n",
            "17  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "18  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "19  0.217430  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "20  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "21  0.000000  0.000000  0.00000  0.00000  0.192110  0.000000  0.291503  \n",
            "22  0.000000  0.000000  0.00000  0.21541  0.141963  0.000000  0.000000  \n",
            "23  0.000000  0.000000  0.32932  0.00000  0.217033  0.000000  0.000000  \n",
            "24  0.000000  0.000000  0.00000  0.00000  0.134513  0.000000  0.000000  \n",
            "25  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "26  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "27  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
            "\n",
            "[28 rows x 297 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Augmented Input**"
      ],
      "metadata": {
        "id": "PPYPOP8rdNeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_input = query+\": \"+best_matching_record"
      ],
      "metadata": {
        "id": "PfEP7i8hdB3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_formatted_response(augmented_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRreLcDgdBNI",
        "outputId": "5f508515-6ecf-4fb7-ceb1-50a8079481d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response -------------------\n",
            "define a rag store: A RAG vector store is a database or dataset that contains vectorized data points.\n",
            "Formatted response -------------------\n",
            "define a rag store: A RAG vector store is a database or dataset that contains\n",
            "vectorized data points.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generation**"
      ],
      "metadata": {
        "id": "NrdxEotPdSga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(augmented_input)\n",
        "print_formatted_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qbb4pDqadRRz",
        "outputId": "c9c484dd-92f2-429c-c6a1-c9609491e2d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response -------------------\n",
            "The given content appears to be a definition of a specific data structure in the field of computer science and mathematics, particularly in the context of Natural Language Processing (NLP) and machine learning. Let's break it down:\n",
            "\n",
            "**Definition:**\n",
            "\n",
            "A RAG (Retrieval-Augmented Generator) vector store is a database or dataset that contains vectorized data points.\n",
            "\n",
            "**Key Components:**\n",
            "\n",
            "1. **RAG**: Stands for Retrieval-Augmented Generator, which is a type of neural network architecture that combines retrieval and generation capabilities.\n",
            "2. **Vector Store**: A vector store is a database or dataset that stores vectorized data points, which are numerical representations of text, images, or other types of data.\n",
            "3. **Vectorized Data Points**: These are numerical representations of text, images, or other types of data, which are used to train machine learning models or perform other tasks.\n",
            "\n",
            "**Purpose:**\n",
            "\n",
            "The purpose of a RAG vector store is to provide a repository of vectorized data points that can be used to train machine learning models, perform similarity searches, or generate new text or data.\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "RAG vector stores have various applications in NLP and machine learning, including:\n",
            "\n",
            "1. **Text Generation**: RAG vector stores can be used to generate new text based on a given prompt or topic.\n",
            "2. **Similarity Search**: RAG vector stores can be used to perform similarity searches, which involve finding the most similar data points to a given query.\n",
            "3. **Information Retrieval**: RAG vector stores can be used to retrieve relevant information from a large corpus of text or data.\n",
            "\n",
            "**Benefits:**\n",
            "\n",
            "The benefits of using a RAG vector store include:\n",
            "\n",
            "1. **Improved Performance**: RAG vector stores can improve the performance of machine learning models by providing a large repository of vectorized data points.\n",
            "2. **Efficient Retrieval**: RAG vector stores can enable efficient retrieval of relevant information from a large corpus of text or data.\n",
            "3. **Flexibility**: RAG vector stores can be used for a variety of tasks, including text generation, similarity search, and information retrieval.\n",
            "\n",
            "In summary, a RAG vector store is a powerful tool for NLP and machine learning applications, providing a repository of vectorized data points that can be used to train machine learning models, perform similarity searches, or generate new text or data.\n",
            "Formatted response -------------------\n",
            "The given content appears to be a definition of a specific data structure in the\n",
            "field of computer science and mathematics, particularly in the context of\n",
            "Natural Language Processing (NLP) and machine learning. Let's break it down:\n",
            "**Definition:**  A RAG (Retrieval-Augmented Generator) vector store is a\n",
            "database or dataset that contains vectorized data points.  **Key Components:**\n",
            "1. **RAG**: Stands for Retrieval-Augmented Generator, which is a type of neural\n",
            "network architecture that combines retrieval and generation capabilities. 2.\n",
            "**Vector Store**: A vector store is a database or dataset that stores vectorized\n",
            "data points, which are numerical representations of text, images, or other types\n",
            "of data. 3. **Vectorized Data Points**: These are numerical representations of\n",
            "text, images, or other types of data, which are used to train machine learning\n",
            "models or perform other tasks.  **Purpose:**  The purpose of a RAG vector store\n",
            "is to provide a repository of vectorized data points that can be used to train\n",
            "machine learning models, perform similarity searches, or generate new text or\n",
            "data.  **Applications:**  RAG vector stores have various applications in NLP and\n",
            "machine learning, including:  1. **Text Generation**: RAG vector stores can be\n",
            "used to generate new text based on a given prompt or topic. 2. **Similarity\n",
            "Search**: RAG vector stores can be used to perform similarity searches, which\n",
            "involve finding the most similar data points to a given query. 3. **Information\n",
            "Retrieval**: RAG vector stores can be used to retrieve relevant information from\n",
            "a large corpus of text or data.  **Benefits:**  The benefits of using a RAG\n",
            "vector store include:  1. **Improved Performance**: RAG vector stores can\n",
            "improve the performance of machine learning models by providing a large\n",
            "repository of vectorized data points. 2. **Efficient Retrieval**: RAG vector\n",
            "stores can enable efficient retrieval of relevant information from a large\n",
            "corpus of text or data. 3. **Flexibility**: RAG vector stores can be used for a\n",
            "variety of tasks, including text generation, similarity search, and information\n",
            "retrieval.  In summary, a RAG vector store is a powerful tool for NLP and\n",
            "machine learning applications, providing a repository of vectorized data points\n",
            "that can be used to train machine learning models, perform similarity searches,\n",
            "or generate new text or data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "amThqZ40dULR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}